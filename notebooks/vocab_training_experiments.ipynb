{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import nltk\n",
    "import ast\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_com_0 = pd.read_csv(\"data/ncbi_comm_use_000000000000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_com_1 = pd.read_csv(\"data/ncbi_comm_use_000000000001.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_non_com_0 =  pd.read_csv(\"data/ncbi_non_comm_use_000000000000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_non_com_1 =  pd.read_csv(\"data/ncbi_non_comm_use_000000000001.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5958, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncbi_com_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4790, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncbi_com_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7924, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncbi_non_com_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9445, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncbi_non_com_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = ncbi_com_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5958, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df1, ncbi_com_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10748, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df2, ncbi_non_com_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18672, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df3, ncbi_non_com_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28117, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newline_char(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return text\n",
    "\n",
    "def nltk_sent_tokenize(text):\n",
    "    text = sent_tokenize(text)\n",
    "    return text\n",
    "\n",
    "def contains_coronavirus(text):\n",
    "    if \"coronavirus\" in text.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def contains_COVID(text):\n",
    "    if \"COVID\" in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # remove rows that have null Body \n",
    "    df = df[~df['Body'].isnull()]\n",
    "    df['Body'] = df['Body'].apply(remove_newline_char)\n",
    "    df['Body_sents'] = df['Body'].apply(nltk_sent_tokenize)\n",
    "    df['Body_tokens'] = df['Body'].apply(word_tokenize)\n",
    "    df['len_body'] = df['Body_tokens'].apply(lambda x: len(x))\n",
    "    df['has_coronavirus'] = df['Body'].apply(contains_coronavirus)\n",
    "    df['has_COVID'] = df['Body'].apply(contains_COVID)\n",
    "    df['len_sents'] = df['Body_sents'].apply(lambda x: len(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and save corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_raw_corpus(df):\n",
    "    raw_corpus = []\n",
    "    for i, row in df.iterrows():\n",
    "        raw_corpus += row['Body_sents']\n",
    "    return raw_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corpus_as_txt(filename, corpus):\n",
    "    with open(filename, 'w') as f:\n",
    "        for sent in corpus:\n",
    "            f.write(sent)\n",
    "            f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tokenizer_input(df, filename):\n",
    "    raw_corpus = build_raw_corpus(df)\n",
    "    save_corpus_as_txt(filename, raw_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SentencePiece tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tokenizer(model_prefix, input_file, vocab_size):\n",
    "    spm.SentencePieceTrainer.train('--model_prefix={} --input={} --vocab_size={}'.format(model_prefix, \n",
    "                                                                                         input_file, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.Load(model_file)\n",
    "    return sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(model, text):\n",
    "    tokenized_text = model.EncodeAsPieces(text)\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows: 5958\n",
    "# vocab_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "//anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "//anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "//anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "//anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 5.109312570095062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "//anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# preprocess data\n",
    "t1 = time.time()\n",
    "df1 = preprocess(df1)\n",
    "t2 = time.time()\n",
    "print (\"Time:\", (t2-t1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.05040566523869832\n"
     ]
    }
   ],
   "source": [
    "# build corpus\n",
    "input_file_1 = \"sample_input_1.txt\"\n",
    "t1 = time.time()\n",
    "raw_corpus_1 = build_tokenizer_input(df1, input_file_1)\n",
    "t2 = time.time()\n",
    "print (\"Time:\", (t2-t1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 6.44949103196462\n"
     ]
    }
   ],
   "source": [
    "# train sp tokenizer\n",
    "model_prefix_1 = \"m1\"\n",
    "vocab_size = 5000\n",
    "t1 = time.time()\n",
    "train_tokenizer(model_prefix_1, input_file_1, vocab_size)\n",
    "t2 = time.time()\n",
    "print (\"Time:\", (t2-t1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_file_1 = model_prefix_1 + \".model\"\n",
    "sp1 = load_model(model_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text\n",
    "text = \"This is a novel coronavirus disease.\"\n",
    "tokenized_text = sp_tokenize(sp1, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁This', '▁is', '▁a', '▁novel', '▁cor', 'on', 'a', 'virus', '▁disease', '.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some EDA on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Refs</th>\n",
       "      <th>Body</th>\n",
       "      <th>Front</th>\n",
       "      <th>Meta</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Body_sents</th>\n",
       "      <th>Body_tokens</th>\n",
       "      <th>len_body</th>\n",
       "      <th>has_coronavirus</th>\n",
       "      <th>has_COVID</th>\n",
       "      <th>len_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aims and Scope Molecular Genetics &amp; Genomic Me...</td>\n",
       "      <td>Mol Genet Genomic MedMol Genet Genomic Medmgg3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...</td>\n",
       "      <td>[Aims and Scope Molecular Genetics &amp; Genomic M...</td>\n",
       "      <td>[Aims, and, Scope, Molecular, Genetics, &amp;, Gen...</td>\n",
       "      <td>622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aims and Scope Molecular Genetics &amp; Genomic Me...</td>\n",
       "      <td>Mol Genet Genomic MedMol Genet Genomic Medmgg3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...</td>\n",
       "      <td>[Aims and Scope Molecular Genetics &amp; Genomic M...</td>\n",
       "      <td>[Aims, and, Scope, Molecular, Genetics, &amp;, Gen...</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The original article to which this erratum ref...</td>\n",
       "      <td>Mol Genet Genomic MedMol Genet Genomic Medmgg3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...</td>\n",
       "      <td>[The original article to which this erratum re...</td>\n",
       "      <td>[The, original, article, to, which, this, erra...</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aims and Scope Molecular Genetics &amp; Genomic Me...</td>\n",
       "      <td>Mol Genet Genomic MedMol Genet Genomic Medmgg3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...</td>\n",
       "      <td>[Aims and Scope Molecular Genetics &amp; Genomic M...</td>\n",
       "      <td>[Aims, and, Scope, Molecular, Genetics, &amp;, Gen...</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In the house of my grandparents in Heinzendorf...</td>\n",
       "      <td>Mol Genet Genomic MedMol Genet Genomic Med10.1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...</td>\n",
       "      <td>[In the house of my grandparents in Heinzendor...</td>\n",
       "      <td>[In, the, house, of, my, grandparents, in, Hei...</td>\n",
       "      <td>1441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Refs                                               Body  \\\n",
       "19  NaN  Aims and Scope Molecular Genetics & Genomic Me...   \n",
       "21  NaN  Aims and Scope Molecular Genetics & Genomic Me...   \n",
       "22  NaN  The original article to which this erratum ref...   \n",
       "23  NaN  Aims and Scope Molecular Genetics & Genomic Me...   \n",
       "24  NaN  In the house of my grandparents in Heinzendorf...   \n",
       "\n",
       "                                                Front Meta  \\\n",
       "19  Mol Genet Genomic MedMol Genet Genomic Medmgg3...  NaN   \n",
       "21  Mol Genet Genomic MedMol Genet Genomic Medmgg3...  NaN   \n",
       "22  Mol Genet Genomic MedMol Genet Genomic Medmgg3...  NaN   \n",
       "23  Mol Genet Genomic MedMol Genet Genomic Medmgg3...  NaN   \n",
       "24  Mol Genet Genomic MedMol Genet Genomic Med10.1...  NaN   \n",
       "\n",
       "                                             Filename  \\\n",
       "19  comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...   \n",
       "21  comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...   \n",
       "22  comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...   \n",
       "23  comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...   \n",
       "24  comm_use.I-N.txt.tar.gz-unpacked/Mol_Genet_Gen...   \n",
       "\n",
       "                                           Body_sents  \\\n",
       "19  [Aims and Scope Molecular Genetics & Genomic M...   \n",
       "21  [Aims and Scope Molecular Genetics & Genomic M...   \n",
       "22  [The original article to which this erratum re...   \n",
       "23  [Aims and Scope Molecular Genetics & Genomic M...   \n",
       "24  [In the house of my grandparents in Heinzendor...   \n",
       "\n",
       "                                          Body_tokens  len_body  \\\n",
       "19  [Aims, and, Scope, Molecular, Genetics, &, Gen...       622   \n",
       "21  [Aims, and, Scope, Molecular, Genetics, &, Gen...       619   \n",
       "22  [The, original, article, to, which, this, erra...       135   \n",
       "23  [Aims, and, Scope, Molecular, Genetics, &, Gen...       619   \n",
       "24  [In, the, house, of, my, grandparents, in, Hei...      1441   \n",
       "\n",
       "    has_coronavirus  has_COVID  len_sents  \n",
       "19                0          0         20  \n",
       "21                0          0         20  \n",
       "22                0          0          4  \n",
       "23                0          0         20  \n",
       "24                0          0         53  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5923\n",
       "1      14\n",
       "Name: has_coronavirus, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.has_coronavirus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5937\n",
       "Name: has_COVID, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.has_COVID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5638.820953343439"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df1['len_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218.91510864072765"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df1['len_sents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
